{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from algoliasearch.search_client import SearchClient\n",
    "\n",
    "client = SearchClient.create(\n",
    "    '7RC58V1YX8',\n",
    "    '37c59621e1c7b8bbba39d600a81f8399'\n",
    ")\n",
    "\n",
    "index = client.init_index('demo_media')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<algoliasearch.responses.IndexingResponse at 0x10a02ead0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.save_objects(posts.json(), {\n",
    "    'autoGenerateObjectIDIfNotExist': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<algoliasearch.responses.IndexingResponse at 0x104edff10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index.set_settings({\n",
    "    # Select the attributes you want to search in\n",
    "    'searchableAttributes': [\n",
    "        'post_title', 'author_name', 'categories', 'content'\n",
    "    ],\n",
    "    # Define business metrics for ranking and sorting\n",
    "    'customRanking': [\n",
    "        'desc(post_date)', 'desc(record_index)'\n",
    "    ],\n",
    "    # Set up some attributes to filter results on\n",
    "    'attributesForFaceting': [\n",
    "        'categories'\n",
    "    ],\n",
    "    # Define the attribute we want to distinct on\n",
    "    'attributeForDistinct': 'post_id'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/2020diatotal.csv\")\n",
    "df = df[df[\"参加初评\"]==\"是\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结获奖情况，从佳作奖/优秀奖,铜奖/三等奖,银奖/二等奖,金奖/一等奖,几个字段中提取出获奖情况\n",
    "def prize_sum(row):\n",
    "    if row[\"佳作奖/优秀奖\"] == \"是\":\n",
    "        return \"佳作奖/优秀奖\"\n",
    "    elif row[\"铜奖/三等奖\"] == \"是\":\n",
    "        return \"铜奖/三等奖\"\n",
    "    elif row[\"银奖/二等奖\"] == \"是\":\n",
    "        return \"银奖/二等奖\"\n",
    "    elif row[\"金奖/一等奖\"] == \"是\":\n",
    "        return \"金奖/一等奖\"\n",
    "    else:\n",
    "        return \"无获奖\"\n",
    "\n",
    "df.loc[:, \"获奖情况文本\"] = df.apply(prize_sum, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = df['作品ID'].to_list()\n",
    "title = df['作品名称(中文)'].to_list()\n",
    "title_en = df['作品名称(英文)'].to_list()\n",
    "year = [\"2022\" for i in range(df.shape[0])]\n",
    "category = df['小类(中文) '].to_list()\n",
    "institution = df['报送单位(中文)'].to_list()\n",
    "author = df['报送人姓名'].to_list()\n",
    "country = df['国籍(中文) '].to_list()\n",
    "country_en = df['国籍(英文) '].to_list()\n",
    "description = df['作品定位描述'].to_list()\n",
    "description_en = df['作品定位描述（英文）'].to_list()\n",
    "innovation = df['设计创新点'].to_list()\n",
    "innovation_en = df['设计创新点（英文）'].to_list()\n",
    "painpoint = df['痛点分析'].to_list()\n",
    "painpoint_en = df['痛点分析（英文）'].to_list()\n",
    "potential = df['潜力与拓展性'].to_list()\n",
    "potential_en = df['潜力与拓展性（英文）'].to_list()\n",
    "prize = df['获奖情况'].to_list()\n",
    "prize_zh = df['获奖情况文本'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把 id title title_en year category institution author country description description_en innovation innovation_en painpoint painpoint_en potential potential_en prize 作为字典的键，把对应的值作为字典的值，组成一个字典数组\n",
    "data_list = [{\"objectID\": id[i], \"title\": title[i], \"title_en\": title_en[i], \"year\": year[i], \"category\": category[i], \"institution\": institution[i], \"author\": author[i], \"country\": country[i], \"country_en\": country_en[i], \"description\": description[i], \"description_en\": description_en[i], \"innovation\": innovation[i], \"innovation_en\": innovation_en[i], \"painpoint\": painpoint[i], \"painpoint_en\": painpoint_en[i], \"potential\": potential[i], \"potential_en\": potential_en[i], \"prize\": prize[i], \"prize_zh\": prize_zh[i]} for i in range(len(id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = client.init_index('dia_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_list_json = json.dumps(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RequestException",
     "evalue": "lexical error: invalid char in json text. Around 'tegory\": N' near line:1 column:204535",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRequestException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index\u001b[39m.\u001b[39;49msave_objects(data_list, {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mautoGenerateObjectIDIfNotExist\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m })\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/search_index.py:68\u001b[0m, in \u001b[0;36mSearchIndex.save_objects\u001b[0;34m(self, objects, request_options)\u001b[0m\n\u001b[1;32m     65\u001b[0m     generate_object_id \u001b[39m=\u001b[39m request_options\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautoGenerateObjectIDIfNotExist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m generate_object_id:\n\u001b[0;32m---> 68\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chunk(\u001b[39m\"\u001b[39;49m\u001b[39maddObject\u001b[39;49m\u001b[39m\"\u001b[39;49m, objects, request_options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     69\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/search_index.py:519\u001b[0m, in \u001b[0;36mSearchIndex._chunk\u001b[0;34m(self, action, objects, request_options, validate_object_id)\u001b[0m\n\u001b[1;32m    516\u001b[0m             assert_object_id(batch)\n\u001b[1;32m    518\u001b[0m         requests \u001b[39m=\u001b[39m build_raw_response_batch(action, batch)\n\u001b[0;32m--> 519\u001b[0m         raw_responses\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_batch(requests, request_options))\n\u001b[1;32m    520\u001b[0m         batch \u001b[39m=\u001b[39m []\n\u001b[1;32m    522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(batch):\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/search_index.py:533\u001b[0m, in \u001b[0;36mSearchIndex._raw_batch\u001b[0;34m(self, requests, request_options)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_batch\u001b[39m(\u001b[39mself\u001b[39m, requests, request_options):\n\u001b[1;32m    531\u001b[0m     \u001b[39m# type: (Union[List[dict], Iterator[dict]], Optional[Union[dict, RequestOptions]]) -> dict # noqa: E501\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transporter\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    534\u001b[0m         Verb\u001b[39m.\u001b[39;49mPOST,\n\u001b[1;32m    535\u001b[0m         endpoint(\u001b[39m\"\u001b[39;49m\u001b[39m1/indexes/\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/batch\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name),\n\u001b[1;32m    536\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mrequests\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mlist\u001b[39;49m(requests)},\n\u001b[1;32m    537\u001b[0m         request_options,\n\u001b[1;32m    538\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/http/transporter.py:35\u001b[0m, in \u001b[0;36mTransporter.write\u001b[0;34m(self, verb, path, data, request_options)\u001b[0m\n\u001b[1;32m     31\u001b[0m timeout \u001b[39m=\u001b[39m request_options\u001b[39m.\u001b[39mtimeouts[\u001b[39m\"\u001b[39m\u001b[39mwriteTimeout\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     33\u001b[0m hosts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mhosts\u001b[39m.\u001b[39mwrite()\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(verb, hosts, path, data, request_options, timeout)\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/http/transporter.py:72\u001b[0m, in \u001b[0;36mTransporter.request\u001b[0;34m(self, verb, hosts, path, data, request_options, timeout)\u001b[0m\n\u001b[1;32m     59\u001b[0m relative_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     60\u001b[0m     path, QueryParametersSerializer\u001b[39m.\u001b[39mserialize(query_parameters)\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     63\u001b[0m request \u001b[39m=\u001b[39m Request(\n\u001b[1;32m     64\u001b[0m     verb\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m     65\u001b[0m     request_options\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mproxies,\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry(hosts, request, relative_url)\n",
      "File \u001b[0;32m~/Desktop/egg/.venv/lib/python3.11/site-packages/algoliasearch/http/transporter.py:91\u001b[0m, in \u001b[0;36mTransporter.retry\u001b[0;34m(self, hosts, request, relative_url)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mcontent \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mcontent:\n\u001b[1;32m     89\u001b[0m             content \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mcontent[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mraise\u001b[39;00m RequestException(content, response\u001b[39m.\u001b[39mstatus_code)\n\u001b[1;32m     93\u001b[0m \u001b[39mraise\u001b[39;00m AlgoliaUnreachableHostException(\u001b[39m\"\u001b[39m\u001b[39mUnreachable hosts\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRequestException\u001b[0m: lexical error: invalid char in json text. Around 'tegory\": N' near line:1 column:204535"
     ]
    }
   ],
   "source": [
    "index.save_objects(data_list, {\n",
    "    'autoGenerateObjectIDIfNotExist': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_list).to_csv(\"./data/2020dia.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
